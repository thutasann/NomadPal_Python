{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db77d6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -------- Static country ranking (no login) --------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CSV_PATH = \"FINALIZED_cities_data.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "if \"City\" not in df.columns:\n",
    "    for c in [\"city\",\"Place\",\"place\"]:\n",
    "        if c in df.columns: df.rename(columns={c:\"City\"}, inplace=True); break\n",
    "if \"Country\" not in df.columns:\n",
    "    for c in [\"country\"]:\n",
    "        if c in df.columns: df.rename(columns={c:\"Country\"}, inplace=True); break\n",
    "\n",
    "def z(s):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    if s.notna().sum() == 0: return pd.Series(0.0, index=s.index)\n",
    "    s = s.fillna(s.median()); std = s.std()\n",
    "    return (s - s.mean()) / (std + 1e-9) if np.isfinite(std) and std != 0 else pd.Series(0.0, index=s.index)\n",
    "\n",
    "# ---- Equal-weight static suitability score\n",
    "parts = []\n",
    "if \"monthly_cost_usd\" in df.columns: parts.append(z(-df[\"monthly_cost_usd\"]))\n",
    "temp_col = next((c for c in [\"weather_avg_temp_c\",\"climate_avg_temp_c\"] if c in df.columns), None)\n",
    "if temp_col:\n",
    "    temp_dev = (pd.to_numeric(df[temp_col], errors=\"coerce\") - 22.0).abs()\n",
    "    parts.append(z(-temp_dev))\n",
    "if \"safety_score\" in df.columns: parts.append(z(df[\"safety_score\"]))\n",
    "df[\"suitability_score\"] = pd.concat(parts, axis=1).mean(axis=1).fillna(0.0) if parts else 0.0\n",
    "\n",
    "# ---- Train model\n",
    "num_feats = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_feats = [c for c in num_feats if c != \"suitability_score\"]\n",
    "cat_feats = [c for c in df.columns if c not in num_feats + [\"suitability_score\"]]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]), num_feats),\n",
    "    (\"cat\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_feats),\n",
    "])\n",
    "model = Pipeline([(\"pre\", pre),\n",
    "                  (\"nn\", MLPRegressor(hidden_layer_sizes=(96,48,16), activation=\"relu\",\n",
    "                                      early_stopping=True, n_iter_no_change=20,\n",
    "                                      random_state=42, max_iter=800))])\n",
    "\n",
    "X = df[num_feats + cat_feats]\n",
    "y = df[\"suitability_score\"]\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_tr, y_tr)\n",
    "\n",
    "# ---- Predict & format JSON\n",
    "df[\"predicted_score\"] = model.predict(X)\n",
    "# Penalize cities with unknown/missing country\n",
    "unknown_mask = (\n",
    "    df[\"Country\"].isna()\n",
    "    | df[\"Country\"].astype(str).str.strip().eq(\"\")\n",
    "    | df[\"Country\"].astype(str).str.contains(r\"^unknown\\b\", case=False, na=True)\n",
    ")\n",
    "\n",
    "UNKNOWN_TOKENS = {\"unknown country\", \"unknown\", \"n/a\", \"na\", \"none\", \"null\", \"\"}\n",
    "mask_unknown = (\n",
    "    df[\"Country\"].isna()\n",
    "    | df[\"Country\"].astype(str).str.strip().str.lower().isin(UNKNOWN_TOKENS)\n",
    "    | df[\"Country\"].astype(str).str.contains(r\"^\\s*unknown\", case=False, na=True)\n",
    ")\n",
    "\n",
    "# Apply very large negative penalty so they sink\n",
    "df.loc[mask_unknown, \"predicted_score\"] = df.loc[mask_unknown, \"predicted_score\"] - 1e9\n",
    "\n",
    "top3_static_rows = df.sort_values(\"predicted_score\", ascending=False).head(3)\n",
    "\n",
    "# Now sort by penalized score, build JSON, and print Top 3\n",
    "import uuid, json\n",
    "from datetime import datetime\n",
    "\n",
    "def city_to_json(row):\n",
    "    return {\n",
    "        \"id\": uuid.uuid4().hex,\n",
    "        \"slug\": str(row[\"City\"]).strip().lower().replace(\" \", \"-\") if \"City\" in row else None,\n",
    "        \"name\": row.get(\"City\"),\n",
    "        \"country\": row.get(\"Country\", \"Unknown Country\"),\n",
    "        \"description\": row.get(\"description\"),\n",
    "        \"monthly_cost_usd\": str(round(row.get(\"monthly_cost_usd\", 0), 2)) if \"monthly_cost_usd\" in row else None,\n",
    "        \"avg_pay_rate_usd_hour\": str(round(row.get(\"avg_pay_rate_usd_hour\", 0), 2)) if \"avg_pay_rate_usd_hour\" in row else None,\n",
    "        \"weather_avg_temp_c\": str(row.get(\"weather_avg_temp_c\")) if \"weather_avg_temp_c\" in row else None,\n",
    "        \"safety_score\": str(row.get(\"safety_score\")) if \"safety_score\" in row else None,\n",
    "        \"nightlife_rating\": str(row.get(\"nightlife_rating\")) if \"nightlife_rating\" in row else None,\n",
    "        \"transport_rating\": str(row.get(\"transport_rating\")) if \"transport_rating\" in row else None,\n",
    "        \"housing_studio_usd_month\": str(row.get(\"housing_studio_usd_month\")) if \"housing_studio_usd_month\" in row else None,\n",
    "        \"housing_one_bed_usd_month\": str(row.get(\"housing_one_bed_usd_month\")) if \"housing_one_bed_usd_month\" in row else None,\n",
    "        \"housing_coliving_usd_month\": str(row.get(\"housing_coliving_usd_month\")) if \"housing_coliving_usd_month\" in row else None,\n",
    "        \"climate_avg_temp_c\": str(row.get(\"climate_avg_temp_c\")) if \"climate_avg_temp_c\" in row else None,\n",
    "        \"climate_summary\": row.get(\"climate_summary\"),\n",
    "        \"internet_speed\": (f'{row.get(\"internet_speed\")} Mbps' if \"internet_speed\" in row else None),\n",
    "        \"cost_pct_rent\": str(row.get(\"cost_pct_rent\")) if \"cost_pct_rent\" in row else None,\n",
    "        \"cost_pct_dining\": str(row.get(\"cost_pct_dining\")) if \"cost_pct_dining\" in row else None,\n",
    "        \"cost_pct_transport\": str(row.get(\"cost_pct_transport\")) if \"cost_pct_transport\" in row else None,\n",
    "        \"cost_pct_groceries\": str(row.get(\"cost_pct_groceries\")) if \"cost_pct_groceries\" in row else None,\n",
    "        \"cost_pct_coworking\": str(row.get(\"cost_pct_coworking\")) if \"cost_pct_coworking\" in row else None,\n",
    "        \"cost_pct_other\": str(row.get(\"cost_pct_other\")) if \"cost_pct_other\" in row else None,\n",
    "        \"travel_flight_from_usd\": str(row.get(\"travel_flight_from_usd\")) if \"travel_flight_from_usd\" in row else None,\n",
    "        \"travel_local_transport_usd_week\": str(row.get(\"travel_local_transport_usd_week\")) if \"travel_local_transport_usd_week\" in row else None,\n",
    "        \"travel_hotel_usd_week\": str(row.get(\"travel_hotel_usd_week\")) if \"travel_hotel_usd_week\" in row else None,\n",
    "        \"lifestyle_tags\": row.get(\"lifestyle_tags\", []),\n",
    "        \"currency\": row.get(\"currency\", \"USD\"),\n",
    "        \"last_updated\": datetime.utcnow().isoformat()\n",
    "    }\n",
    "\n",
    "# Top 3 cities (static, penalized)\n",
    "top3_static_rows = df.sort_values(\"predicted_score\", ascending=False).head(3)\n",
    "top3_static_json = [city_to_json(r) for _, r in top3_static_rows.iterrows()]\n",
    "\n",
    "print(json.dumps(top3_static_json, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
